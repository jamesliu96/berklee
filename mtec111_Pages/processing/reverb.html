<html>
<head>
<title>Reverb</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link rel="stylesheet" href="../../DTMP_reference/Week1/musicianship101.css" type="text/css">
<script language="JavaScript">
<!--
function MM_reloadPage(init) {  //reloads the window if Nav4 resized
  if (init==true) with (navigator) {if ((appName==&quot;Netscape&quot;)&&(parseInt(appVersion)==4)) {
    document.MM_pgW=innerWidth; document.MM_pgH=innerHeight; onresize=MM_reloadPage; }}
  else if (innerWidth!=document.MM_pgW || innerHeight!=document.MM_pgH) location.reload();
}
MM_reloadPage(true);
// -->
</script>
</head>

<body bgcolor="#FFFFFF" text="#000000">
<h3 class="topic_header"><a name="top"></a><font face="Verdana, Arial, Helvetica, sans-serif">Reverb</font></h3>
<hr>
<p class="body"> We use the sense of hearing to get many of our cues about the 
  space around us. We can usually tell the size and shape of an acoustic space 
  from these auditory cues. We can easily hear the difference between a room when 
  it's empty and when it's filled with people, or one that's made of tile and 
  cinder blocks and one that's has wood paneling and carpets. </p>
<p class="body">We use reverb to artificially create a sense of space. In the 
  physical world, all musical performances take place in some sort of room or 
  hall. Since many of our instruments are virtual in desktop production, we'll 
  need to use reverb to put them in some spatial perspective. We'll often want 
  to place audio recordings in a space other than where they were originally recorded. 
  We probably wouldn't want our vocalist, perhaps the next big pop diva, to sound 
  like she was singing in a basement, now would we?</p>
<p class="body">Spatialization created using reverb is the result of a direct, 
  unprocessed signal being mixed with a number of closely spaced, random echoes. 
  A combination of three factors gives us cues on what a particular space sounds 
  like:</p>
<ul>
  <li>the sound we hear directly from a source</li>
  <li>the first sounds reflected from nearby surfaces called <b>early reflections</b></li>
  <li>multiple waves of reflected sound as the sound from the original source 
    continues to be reflected</li>
</ul>
<p>Take a look at the following diagram. We see each of these illustrated on a 
  graph showing the number and level of reflected sound over time.</p>
<p align="center"><img src="assets/3component_of_reverb.gif" width="600" height="390"></p>
<p align="center"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Components 
  of Reverberation</font></p>
<p><font color="#000000"> What we also notice is that the loudest sound we hear 
  is the direct sound, and as early reflections continue into reverberant sound, 
  the number and density of reflections increases, while the loudness of the reflections 
  decays. </font></p>
<p></p>
<hr>
<p><strong><font face="Verdana, Arial, Helvetica, sans-serif">RV7000</font></strong></p>
<p>Take a look at the <strong>RV7000</strong> reverb found in Reason. Compare 
  the display in the Remote Programmer to the <em>Components of Reverberation</em> 
  diagram above. Many current reverb units and plug-ins display parameters graphically. 
  Additional controls allow you to simulate spaces of different size shape and 
  material. In reflective surfaces, such as tile or brick, reflections will be 
  brighter. Porous surfaces, such as carpeting and curtains will soak up higher 
  frequencies so their reflections will sound duller. We can control this using 
  the HF Damp and Hi EQ, two variations on spectrum filters. </p>
<p>&nbsp;</p>
<p align="center"><img src="assets/RV7000.gif" width="750" height="202" border="2"></p>
<hr>
<p>&nbsp;</p>
<div align="center"></div>
</body>
</html>